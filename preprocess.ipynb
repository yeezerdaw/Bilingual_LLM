{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8287d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['output', 'input', 'instruction'],\n",
      "        num_rows: 51760\n",
      "    })\n",
      "})\n",
      "\n",
      "--- TRAIN ---\n",
      "Dataset({\n",
      "    features: ['output', 'input', 'instruction'],\n",
      "    num_rows: 51760\n",
      "})\n",
      "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.', 'input': '', 'instruction': 'Give three tips for staying healthy.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "alpaca_dataset = load_from_disk(\"data/alpaca\")\n",
    "print(alpaca_dataset)\n",
    "\n",
    "# Show basic info and first few rows\n",
    "for split, data in alpaca_dataset.items():\n",
    "    print(f\"\\n--- {split.upper()} ---\")\n",
    "    print(data)\n",
    "    print(data[0])\n",
    "    break  # we just need one example for structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1e5fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51760, 3)\n",
      "\n",
      "Column-wise missing values:\n",
      "output         0\n",
      "input          0\n",
      "instruction    0\n",
      "dtype: int64\n",
      "\n",
      "Empty 'input' rows: 32603/51760\n",
      "\n",
      "Examples with non-empty 'input':\n",
      "[{'output': 'The fraction 4/16 is equivalent to 1/4 because both fractions represent the same value. A fraction can be simplified by dividing both the numerator and the denominator by a common factor. In this case, 4 is a common factor of both the numerator and the denominator of 4/16. When we divide both by 4, we get 4/4 = 1 and 16/4 = 4, so the simplified fraction is 1/4. Alternatively, we can think of this in terms of multiplication. For example, if we multiply the numerator and denominator of the fraction 1/4 by 4, we get (1x4)/(4x4), or 4/16. Since both fractions can be derived from the other through multiplication or division by the same number, they represent the same value and are equivalent.', 'input': '4/16', 'instruction': 'Explain why the following fraction is equivalent to 1/4'}, {'output': 'There are two spelling errors in the sentence. The corrected sentence should be: \"He finished his meal and left the restaurant.\"', 'input': 'He finnished his meal and left the resturant', 'instruction': 'Evaluate this sentence for spelling and grammar mistakes'}, {'output': 'Animals: Elephant\\nPlants: Oak tree\\nMinerals: Copper ore', 'input': 'Oak tree, copper ore, elephant', 'instruction': 'Classify the following into animals, plants, and minerals'}, {'output': \"```\\n# This is a function that calculates the factorial of a given number\\ndef factorialize(num):\\n  # Set the variable 'factorial' to 1\\n  factorial = 1\\n  # Iterate from 1 to 'num' using the range function\\n  for i in range(1, num):\\n    # Multiply the 'factorial' variable by the current number in the iteration\\n    factorial *= i\\n  # Return the final value of 'factorial'\\n  return factorial\\n```\", 'input': 'def factorialize(num):\\n  factorial = 1\\n  for i in range(1, num):\\n    factorial *= i\\n  \\n  return factorial', 'instruction': 'Refactor this code and add comments.'}, {'output': 'She will play the piano beautifully for hours and then stop as it will be midnight.', 'input': 'She played the piano beautifully for hours and then stopped as it was midnight.', 'instruction': 'Based on the information provided, rewrite the sentence by changing its tense from past to future.'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the train split into a DataFrame\n",
    "alpaca_df = alpaca_dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Basic stats\n",
    "print(\"Shape:\", alpaca_df.shape)\n",
    "print(\"\\nColumn-wise missing values:\")\n",
    "print(alpaca_df.isna().sum())\n",
    "\n",
    "# Count how many have empty 'input'\n",
    "empty_input_count = (alpaca_df['input'].str.strip() == '').sum()\n",
    "print(f\"\\nEmpty 'input' rows: {empty_input_count}/{len(alpaca_df)}\")\n",
    "\n",
    "# Preview a few examples where input is NOT empty\n",
    "print(\"\\nExamples with non-empty 'input':\")\n",
    "print(alpaca_df[alpaca_df['input'].str.strip() != ''].head(5).to_dict(orient='records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8fe6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'Instruction: Explain what data preprocessing is and three steps used in the process.', 'response': 'Data preprocessing is an important step in the data analysis and machine learning process. It involves the transformation of raw data into a usable format, so that it can be effectively used in machine learning algorithms, predictive modeling or data mining techniques. The aim of data preprocessing is to improve the quality and accuracy of the data by eliminating any inconsistencies, errors or missing values, and to prepare the data for further analysis. \\n\\nThere are several steps involved in the data preprocessing process, some of which includes:\\n\\n1. Data Cleaning: This involves checking and correcting errors in the data such as duplicate records, mislabeled data points or invalid values. It also involves filling in missing values or removing records that do not meet certain criteria.\\n\\n2. Data Transformation: This involves converting the data to a standard format, so that it can be easily understood and analyzed. Data transformation can involve scaling, normalization or encoding of the data.\\n\\n3. Data Reduction: This involves reducing the amount of data that needs to be analyzed, by selecting only the most relevant features or records. Data reduction techniques such as Principal Component Analysis, Agglomerative Clustering or Sampling can be used to achieve this.\\n\\nIn summary, data preprocessing is an important step in preparing data for analysis, and it involves several steps such as data cleaning, transformation and reduction to improve the quality and accuracy of the data.'}, {'prompt': 'Instruction: What is the product of 6 and 2?', 'response': 'The product of 6 and 2 is 12.'}, {'prompt': 'Instruction: Recognize the sentiment in the following tweet.\\nInput: I love my job.', 'response': 'The sentiment expressed in the tweet \"I love my job\" is positive.'}]\n",
      "\n",
      "Final shape: (51760, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "alpaca_df = alpaca_dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Merge instruction + input into one field\n",
    "def merge_prompt(row):\n",
    "    if row[\"input\"].strip():\n",
    "        return f\"Instruction: {row['instruction'].strip()}\\nInput: {row['input'].strip()}\"\n",
    "    else:\n",
    "        return f\"Instruction: {row['instruction'].strip()}\"\n",
    "\n",
    "alpaca_df[\"prompt\"] = alpaca_df.apply(merge_prompt, axis=1)\n",
    "alpaca_df[\"response\"] = alpaca_df[\"output\"].astype(str).str.strip()\n",
    "\n",
    "# Keep only the useful columns\n",
    "alpaca_clean = alpaca_df[[\"prompt\", \"response\"]]\n",
    "\n",
    "print(alpaca_clean.sample(3).to_dict(orient=\"records\"))\n",
    "print(\"\\nFinal shape:\", alpaca_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed69b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/85/5_4w11lj2vv3mvmb5v4wkqr40000gn/T/ipykernel_84458/3585068580.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alpaca_clean[\"prompt\"] = alpaca_clean[\"prompt\"].apply(clean_text)\n",
      "/var/folders/85/5_4w11lj2vv3mvmb5v4wkqr40000gn/T/ipykernel_84458/3585068580.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alpaca_clean[\"response\"] = alpaca_clean[\"response\"].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # collapse multiple spaces/newlines\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "alpaca_clean[\"prompt\"] = alpaca_clean[\"prompt\"].apply(clean_text)\n",
    "alpaca_clean[\"response\"] = alpaca_clean[\"response\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36a47fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned Alpaca dataset saved to data_cleaned/alpaca_clean.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "alpaca_clean.to_json(\"data_cleaned/alpaca_clean.jsonl\", orient=\"records\", lines=True)\n",
    "print(\"✅ Cleaned Alpaca dataset saved to data_cleaned/alpaca_clean.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78065870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 4)\n",
      "\n",
      "Column names: ['id', 'system_prompt', 'question', 'response']\n",
      "\n",
      "Sample rows:\n",
      "[{'id': 'niv.242684', 'system_prompt': nan, 'question': \"You will be given a definition of a task first, then some input of the task.\\nThis task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\\n\\nAFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\\nOutput:\", 'response': '[\\n  [\"AFC Ajax (amateurs)\", \"has ground\", \"Sportpark De Toekomst\"],\\n  [\"Ajax Youth Academy\", \"plays at\", \"Sportpark De Toekomst\"]\\n]'}, {'id': 'flan.564327', 'system_prompt': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.', 'question': 'Generate an approximately fifteen-word sentence that describes all this data: Midsummer House eatType restaurant; Midsummer House food Chinese; Midsummer House priceRange moderate; Midsummer House customer rating 3 out of 5; Midsummer House near All Bar One', 'response': 'Midsummer House is a moderately priced Chinese restaurant with a 3/5 customer rating, located near All Bar One.'}, {'id': 'flan.1875913', 'system_prompt': 'You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old.', 'question': 'What happens next in this paragraph?\\n\\nShe then rubs a needle on a cotton ball then pushing it onto a pencil and wrapping thread around it. She then holds up a box of a product and then pouring several liquids into a bowl. she\\nChoose your answer from: A. adds saucepan and shakes up the product in a grinder. B. pinches the thread to style a cigarette, and then walks away. C. then dips the needle in ink and using the pencil to draw a design on her leg, rubbing it off with a rag in the end. D. begins to style her hair and cuts it several times before parting the ends of it to show the hairstyle she has created.', 'response': 'C. She then dips the needle in ink and using the pencil to draw a design on her leg, rubbing it off with a rag in the end. In this option, she is continuing the process of using the needle, pencil, and thread, which is most related to what she was doing in the previous sentence.'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the OpenOrca subset\n",
    "df_orca = pd.read_csv(\"data/open_orca_subset.csv\")\n",
    "print(\"Shape:\", df_orca.shape)\n",
    "print(\"\\nColumn names:\", df_orca.columns.tolist())\n",
    "\n",
    "# Show the first few rows to understand structure\n",
    "print(\"\\nSample rows:\")\n",
    "print(df_orca.head(3).to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8646246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with system_prompt: 92427/100000\n",
      "\n",
      "Examples WITH system_prompt:\n",
      "[{'id': 'flan.564327', 'system_prompt': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.', 'question': 'Generate an approximately fifteen-word sentence that describes all this data: Midsummer House eatType restaurant; Midsummer House food Chinese; Midsummer House priceRange moderate; Midsummer House customer rating 3 out of 5; Midsummer House near All Bar One', 'response': 'Midsummer House is a moderately priced Chinese restaurant with a 3/5 customer rating, located near All Bar One.'}, {'id': 'flan.1875913', 'system_prompt': 'You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old.', 'question': 'What happens next in this paragraph?\\n\\nShe then rubs a needle on a cotton ball then pushing it onto a pencil and wrapping thread around it. She then holds up a box of a product and then pouring several liquids into a bowl. she\\nChoose your answer from: A. adds saucepan and shakes up the product in a grinder. B. pinches the thread to style a cigarette, and then walks away. C. then dips the needle in ink and using the pencil to draw a design on her leg, rubbing it off with a rag in the end. D. begins to style her hair and cuts it several times before parting the ends of it to show the hairstyle she has created.', 'response': 'C. She then dips the needle in ink and using the pencil to draw a design on her leg, rubbing it off with a rag in the end. In this option, she is continuing the process of using the needle, pencil, and thread, which is most related to what she was doing in the previous sentence.'}, {'id': 't0.408370', 'system_prompt': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.', 'question': 'Please answer the following question: I want to test the ability of students to read a passage and answer questions about it. Could you please come up with a good question for the passage \"In 1901, the Federation of Australia was the process by which the six separate British self-governing colonies of New South Wales, Queensland, South Australia, Tasmania, Victoria and Western Australia formed one nation. They kept the systems of government that they had developed as separate colonies but also would have a federal government that was responsible for matters concerning the whole nation. When the Constitution of Australia came into force, the colonies collectively became states of the Commonwealth of Australia.\"?\\nAnswer:', 'response': 'Based on the passage, discuss the primary motivations and outcomes of the 1901 Federation of Australia, including the roles and responsibilities of the federal government, as well as the continued governmental structures of the individual states involved.'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_orca = pd.read_csv(\"data/open_orca_subset.csv\")\n",
    "\n",
    "# Count system prompts\n",
    "has_system = df_orca['system_prompt'].notna().sum()\n",
    "print(f\"Rows with system_prompt: {has_system}/{len(df_orca)}\")\n",
    "\n",
    "# Quick look at a few with system prompts\n",
    "print(\"\\nExamples WITH system_prompt:\")\n",
    "print(df_orca[df_orca['system_prompt'].notna()].head(3).to_dict(orient='records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ee6603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'System: You are an AI assistant. Provide a detailed answer so user don’t need to search outside to understand the answer. User: Definition: In this task, you\\'re given reviews from Amazon\\'s food products and a summary of that review. Your task is to classify whether the given summary matches the original review. Generate \"True\" if the given review and its summary match, otherwise generate \"False\". Input: Reviews: Classic Lynch and a horrible transfer. Grainy in many scenes. My Dvd Edition looks better. Summary: The suspenders are fine, sort of...the packaging not so much. Output:', 'response': 'False'}, {'prompt': \"System: You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old. User: Translate the following sentence to Czech: And I don't think there's a demon in this court Who could fill the cloven hooves\", 'response': 'A já si nemyslím, že je tady v tomto soudu nějaký démon, který by dokázal zaplnit rozštěpené kopyto.'}, {'prompt': 'System: You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps. User: What is a one-sentence summary of the following article? Begin by visiting http://www.aaa.com. The AAA is actually made up of many organizations, serving different areas. However, you can reach any of these regional organizations by visiting this website. Note: start with this step even if you plan to apply for membership in person, not online. The AAA website may automatically detect the general area you are located in, and send you to the correct web page for your area. If it does not, it will likely display a popup box and prompt you to enter your zip code. If you do not know your zip code, you may look it up by entering your address at the US Postal Service website. Some local AAA organizations display their regional address prominently on the front page of their website, which you were just directed to. If you do not see one, or if the address is not nearby, look for a \"Find another office\" link, or \"Find a local branch,\" or similar. Click this link to be taken to a map or a list of all AAA offices in your region, including their phone numbers and hours of operation. Try using your browser\\'s Find command and enter \"Office\" or \"Branch.\" This is typically available with the Ctrl+F key combination in a Windows operating system, or command+F on a Mac. Optionally, call the listed phone number and ask for information on membership plans. Your local office may or may not be able to register you as a member over the phone. Almost any AAA office should be able to register you in person, as long as you bring your driver\\'s license and a method of payment. To save time before you show up, know what type of vehicles you operate, and whether other members of your household wish to apply as well. There are dozens of regional websites, organized in many different layouts. Somewhere on the homepage, however, there should be a button or text link labeled Join Now or Join AAA. When you click Join, you will likely be taken to a chart comparing the benefits of different membership plans. The details of these vary between regional organizations, but the benefits are typically laid out clearly in a chart. Usually, the organization offers Classic (or Basic), Plus, and Premier membership. The Plus and Premier memberships cost more, but come with additional perks as described, such as additional free towing, or free travel insurance under certain conditions. If you do not understand a particular perk, the name of the perk may be a link that describes it in more detail. Other AAA websites have a question mark to click next to it, or a \"View details\" link at the bottom of the chart. The \"Primary Member\" price indicates how much you would pay each year for that membership. There is typically an additional \"Enrollment\" fee or \"New Member\" fee, which is an additional charge applied once, when you join. Finally, if you wish another member of your household to receive the same benefits, that may cost you an additional \"Associate Member\" fee each year, per additional member. The Classic or Basic plan typically only covers ordinary cars, not RVs, trailers, or motorcycles. Your regional organization may display detailed information on this in a Vehicle Types chart at the bottom of the page, or include it somewhere in the perk list. After selecting \"Join\" for a particular plan, you should be taken to a form. Enter your full name, personal information, and contact information, as directed. When you\\'re done, hit next. You may be prompted for additional information, such as associate member information. Look for a \"Convenience Billing\" option. Select \"No\" if you do not want your credit card to be automatically billed at the end of each year. Keep it selected \"Yes\" if you want to automatically renew your membership each year. If you disable convenience billing, you will need to manually pay your membership dues each year to retain membership benefits. Enter your credit card information, or your personal checking account information. After confirming the order via email, your membership card should arrive in the mail within a few days. Do not enter your credit card information over an unsecured internet network, especially a public one used by many people.', 'response': \"Visit AAA's website to locate the right regional organization, then follow the prompts to choose a membership plan, input personal information, and select payment preferences, all while utilizing a secure internet network to protect your sensitive information.\"}]\n",
      "\n",
      "Final shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "df_orca = pd.read_csv(\"data/open_orca_subset.csv\")\n",
    "\n",
    "# Merge into single prompt field\n",
    "def merge_prompt(row):\n",
    "    sys_prompt = str(row[\"system_prompt\"]) if not pd.isna(row[\"system_prompt\"]) else \"\"\n",
    "    question = str(row[\"question\"]).strip()\n",
    "    if sys_prompt.strip():\n",
    "        return f\"System: {sys_prompt.strip()}\\n\\nUser: {question}\"\n",
    "    else:\n",
    "        return f\"User: {question}\"\n",
    "\n",
    "df_orca[\"prompt\"] = df_orca.apply(merge_prompt, axis=1)\n",
    "df_orca[\"response\"] = df_orca[\"response\"].astype(str).str.strip()\n",
    "\n",
    "# Light cleanup — remove weird spacing\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_orca[\"prompt\"] = df_orca[\"prompt\"].apply(clean_text)\n",
    "df_orca[\"response\"] = df_orca[\"response\"].apply(clean_text)\n",
    "\n",
    "# Keep only useful columns\n",
    "df_orca_clean = df_orca[[\"prompt\", \"response\"]]\n",
    "\n",
    "# Quick preview\n",
    "print(df_orca_clean.sample(3).to_dict(orient=\"records\"))\n",
    "print(\"\\nFinal shape:\", df_orca_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f79579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned OpenOrca dataset saved to data_cleaned/open_orca_clean.jsonl\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "df_orca_clean.to_json(\"data_cleaned/open_orca_clean.jsonl\", orient=\"records\", lines=True)\n",
    "print(\"✅ Cleaned OpenOrca dataset saved to data_cleaned/open_orca_clean.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ec1152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model loaded\n",
      "Counter({'__label__ta': 177})\n"
     ]
    }
   ],
   "source": [
    "import fasttext, json, random\n",
    "from collections import Counter\n",
    "\n",
    "model = fasttext.load_model(\"lid.176.bin\")\n",
    "print(\"✅ model loaded\")\n",
    "\n",
    "# sample and test\n",
    "path = \"data_cleaned/tamil_wikipedia_clean.jsonl\"\n",
    "sample_texts = []\n",
    "with open(path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i % 1000 == 0:\n",
    "            sample_texts.append(json.loads(line)[\"text\"])\n",
    "        if len(sample_texts) >= 200:\n",
    "            break\n",
    "\n",
    "def safe_predict(text):\n",
    "    labels, _ = model.predict(text[:500])\n",
    "    return labels[0] if labels else \"__label__unknown\"\n",
    "\n",
    "predictions = [safe_predict(t) for t in sample_texts]\n",
    "from collections import Counter\n",
    "counts = Counter(predictions)\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465c7fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering Tamil-only lines: 176887it [00:09, 19049.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tamil-only filtered corpus saved to: data_cleaned/tamil_wikipedia_tamil_only.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json, fasttext, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = fasttext.load_model(\"lid.176.bin\")\n",
    "\n",
    "input_path = \"data_cleaned/tamil_wikipedia_clean.jsonl\"\n",
    "output_path = \"data_cleaned/tamil_wikipedia_tamil_only.jsonl\"\n",
    "\n",
    "with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
    "    for line in tqdm(infile, desc=\"Filtering Tamil-only lines\"):\n",
    "        article = json.loads(line)\n",
    "        text = article[\"text\"]\n",
    "        label, prob = model.predict(text[:500])\n",
    "        if label[0] == \"__label__ta\" and prob[0] > 0.85:\n",
    "            json.dump(article, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Tamil-only filtered corpus saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8b3119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"குழந்தை பராமரிப்பு | தினகரன்\\nHome குழந்தை பராமரிப்பு\\nகுழந்தைகளின் செய்கை மொழியை எளிதில் புரிந்து கொள்ள இயலாது. அழுகையும், சிரிப்புமே குழந்தையின் அழகிய மொழிகள். அதனை உணர்ந்து குழந்தைகளை வளர்ப்பது என்பது பெற்றோருக்கே உண்டான தனிக்கலை. பச்சிளம் குழந்தைகளின் செயல்பாடுகள் புரியாமல் சில நேரங்களில் தாய்மார்கள் எரிச்சல் அடைவதும் உண்டு. இங்கு குழந்தைகளை எவ்வாறு கையாள வேண்டும்.\\n1. குழந்தைகள் முதலில் விரும்புவது தாயின் அரவணைப்பையும், அருகாமையையும் தான். அந்த கதகதப்பு கிடைக்காத பட்சத்தில் அதற்காகவே அழுகையை தொடங்குகிறார்கள். எனவே குழந்தைகள் அழும் போது அவர்களை தூக்கி கொஞ்சினால் குழந்தைகள் உடனே அழுகையை நிறுத்திவிடுவார்கள். அந்த நேரத்தில் குழந்தைகளுக்கு உணவூட்டுதல், மசாஜ் அல்லது குளிக்க வைக்கவோ செய்யலாம்.\\n2. குழந்தையைத் தூக்கும்போது முதுகுப் புறமாக அதிகமாகப் பிடித்துத் தூக்கக்கூடாது, அது குழந்தையின் தண்டுவடத்தைப் பாதிக்கும் என்று சிலர் சொல்வார்கள். ஆனால் உண்மையில்லை. பின்னால் பிடித்துத் தூக்குவது குழந்தையின் ரிப்ளெக்ஸ்' திறனை மேம்படுத்துகிறது. பின்புற மற்றும் கழுத்துத் தசைகளையும், தண்டுவடத்துக்குத் துணையாக உள்ள தசைகளையும் வலுப்படுத்துகிறது\\n3. குழந்தைக்குப் பாலூட்டும்போது அதை மார்பகத்தை நோக்கி அழுத்த வேண்டாம். அப்போது குழந்தை அதன் இயல்பின்படி தனது தலையைப் பின்னோக்கித் தள்ளும். எனவே கைகளில் லேசாக ஏந்தி அதற்கு ஏற்ற வகையில் பாலூட்டுவதே சிறப்பானது. குழந்தைகளுக்கு மூச்சுத்திணறல் ஏற்படுவதையும் தடுக்கும். ஒரு சிலர் படுத்துக் கொண்டே பாலூட்டுவார்கள். இது சில சமயங்களில் ஆபத்தை ஏற்படுத்தும்.\\n4. இளந்தாய்மார்கள் குழந்தையை எப்படி குளிப்பாட்டுவது என்று தெரியாமல் திகைத்துப் போகிறார்கள். அந்நேரத்தில் குழந்தை அழுதால் என்ன செய்வது என்று புரியாமல் தடுமாறிப் போகிறார்கள். பெரியவர்கள் அல்லது கணவரின் துணையோடு குழந்தையை குளிப்பாட்டலாம். எப்பொழுதுமே வெதுவெதுப்பான நீரில் குளிப்பாட்ட வேண்டும். குளித்த பின் மெல்லிய உலர்ந்த துணியை பயன்படுத்தி நன்றாக துடைத்து எடுப்பது நல்லது.\\n5. குழந்தைகளுக்கு காற்றோட்டமான, மெல்லிய துணி ஆடைகளை அணிவிக்கலாம். அது குழந்தையின் இயல்பான உடல் வெப்பநிலையைப் பராமரிக்க உதவுவதுடன், புற வெப்பநிலையிலிருந்தும் பாதுகாக்கும். குழந்தையின் இடுப்பு ஆடையை அடிக்கடி மாற்றத் தவறுவதால் நோய்த் தொற்று ஏற்படலாம். குழந்தையின் சருமத்தைச் சுத்தமாகவும், உலர்வாகவும், வாசனையற்றும் வைத்துக்கொள்வது முக்கியம். அது நோய் தொற்றில் இருந்து பாதுகாக்கும்.\\n6. குழந்தையை தூங்கவைக்க ஒரு சிலர் மிகவும் சிரமப்படுவார்கள். வெளியே வேடிக்கை காட்டுவது, காரில் அழைத்துச் செல்வது என பணத்தையும், நேரத்தையும் வீணாக்குவார்கள். அது போன்ற தேவையற்ற செயல்களை தவிர்த்து, குழந்தையை அதன் சக்கர நாற்காலியில் வைத்து மெதுவாக உருட்டலாம். அப்போது ஏற்படும் மெல்லிய அதிர்வு, நகர்வுக்குக் குழந்தை பழகி தூங்கத் தொடங்கி விடும். குழந்தையின் நெற்றி, நெஞ்சு அல்லது பின்புறத்தில் மெதுவாகத் தட்டுவது ஒரு தூண்டலாகச் செயல்பட்டு குழந்தையைத் தூக்கத்தில் ஆழ்த்துகிறது. அப்போது எழும் ஓசை நேர்மறை பலனைத் தருகிறதாம்.\",\n",
      "  \"timestamp\": \"2020/07/06 20:32:10\",\n",
      "  \"url\": \"http://www.thinakaran.lk/2019/11/16/%E0%AE%95%E0%AF%81%E0%AE%B1%E0%AE%BF%E0%AE%AA%E0%AF%8D%E0%AE%AA%E0%AF%81%E0%AE%95%E0%AE%B3%E0%AF%8D/44001/%E0%AE%95%E0%AF%81%E0%AE%B4%E0%AE%A8%E0%AF%8D%E0%AE%A4%E0%AF%88-%E0%AE%AA%E0%AE%B0%E0%AE%BE%E0%AE%AE%E0%AE%B0%E0%AE%BF%E0%AE%AA%E0%AF%8D%E0%AE%AA%E0%AF%81\",\n",
      "  \"source\": \"mC4\"\n",
      "}\n",
      "{\n",
      "  \"text\": \"பிரிட்ஜ் பராமரிப்பு! | சிறுவர் மலர் | Siruvarmalar | tamil weekly supplements\\n* பிரிட்ஜை அடுப்பு அறையில் வைக்க கூடாது. புகை பட்டு நிறம் போய்விடும்.\\n* பிரிட்ஜை அடிக்கடி திறக்க கூடாது; திறந்தால் உடனே மூடி விட வேண்டும்.\\n* பிரீசரில் உள்ள ஐஸ் தட்டுகள் எடுக்க வரவில்லை எனில் கத்தியை வைத்து குத்த கூடாது. அதற்கு பதில், பழைய காஸ்கட்டை போட்டு அதன்மேல் வைத்தாலோ அல்லது சிறிது கல் உப்பை தூவி வைத்து அதன் மேல் ஐஸ் தட்டை வைத்தாலோ சுலபமாக எடுக்க வரும்.\\n* பிரிட்ஜில் வைக்கும் பொருள்களின் மீது நீர்த்துளிகள் கண்டிப்பாக படிந்து இருக்க கூடாது. நன்கு துடைத்து வைக்க வேண்டும்.\\n* அதிகப்படியாக பொருள்களை அடைத்து வைக்க கூடாது. பெட்டிக்குள் வைக்கப்படும் ஒவ்வொரு பொருளுக்கும் காற்று செல்வதற்கு ஏற்ப சிறிது இடைவெளி விட்டு வைக்க வேண்டும்.\\n* பிரிட்ஜை இதமாக திறந்து மூட வேண்டும்.\\n* பிரிட்ஜ் முன் ரப்பர் உறையை விரித்து, அதன் மீது ஏறி நின்று, பிரிட்ஜை திறந்தால் ஷாக் அடிக்காது.\\n* பச்சை காய்கறிகளை, 'பாலிதீன்' கவர்களில் போட்டு வைக்கவும்.\\n* பிரிட்ஜில் வைக்கும் பாட்டில்களை, அடிக்கடி சுத்தம் செய்து வெயிலில் காய வைத்து உபயோகப்படுத்த வேண்டும்.\\n* வாழைப்பழத்தை எக்காரணம் கொண்டும் பிரிட்ஜில் வைக்க கூடாது.\\n* பச்சைமிளகாய் வைக்கும் போது, அதன் காம்பை எடுத்து விட்டு தான் வைக்க வேண்டும்.\\n* பிரிட்ஜில் வைக்கப்படும் எந்த உணவு வகையானாலும் மூடி வைக்கவும்.\\n* பிரிட்ஜிலிருந்து துர்நாற்றம் வீசாமல் இருக்க, அதனுள் எப்போதும் சிறிது புதினா இலையையோ, சாறு எடுத்த எலுமிச்சம் பழ மூடிகளையோ வைக்கலாம்.\\n* தயிரை கடைந்து சிறிது நேரம் பிரிட்ஜில் வைத்தால், எளிதாக வெண்ணெய் திரளும்.\\n* வெங்காயத்தை பிளாஸ்டிக் கவரில் போட்டு பிரிட்ஜில் இரண்டு மணி நேரம் வைத்து நறுக்கினால் கண் கலங்காது.\\n* உருளைக்கிழங்கு, வெங்காயம், பூண்டு முதலியவற்றை பிரிட்ஜில் வைக்க வேண்டாம்.\\n* பிரிட்ஜில் வைத்துள்ள காய்கறிகளை, இரண்டு மணி நேரத்திற்கு முன், எடுத்து வைத்து சமைத்தால் எரிபொருள் மிச்சமாகும்.\\n* முந்தைய நாளே காய்கறியை அரிந்து இறுக்கமாக பாலிதீன் கவரில் போட்டு பிரிட்ஜில் வைத்தால், வைட்டமின் சத்துக்கள் அப்படியே இருக்கும்.\",\n",
      "  \"timestamp\": \"2019/12/09 19:10:45\",\n",
      "  \"url\": \"https://www.dinamalar.com/supplementary_detail.asp?id=34539&ncat=3\",\n",
      "  \"source\": \"mC4\"\n",
      "}\n",
      "{\n",
      "  \"text\": \"தஞ்சை தேர் விபத்தில் 11 பேர் பலி… மத்திய, மாநில அரசுகளின் சார்பில் நிவாரணம் அறிவிப்பு.. அரசியல் தலைவர்கள் இரங்கல்…!! – Update News 360 | Tamil News Online | Live News | Breaking News Online | Latest Update News\\nதஞ்சை தேர் விபத்தில் 11 பேர் பலி… மத்திய, மாநில அரசுகளின் சார்பில் நிவாரணம் அறிவிப்பு.. அரசியல் தலைவர்கள் இரங்கல்…!!\\n27 April 2022, 10:28 am\\nதஞ்சாவூர்‌ மாவட்டம்‌ களிமேடு கிராமத்தில்‌ மின்சார விபத்தில்‌ உயிரிழந்த குடும்பத்தினருக்கு மத்திய, மாநில அரசுகளின் சார்பில் நிவாரணம் அறிவிக்கப்பட்டுள்ளது.\\nஇந்த விபத்து சம்பவம் தொடர்பாக அறிக்கை வெளியிட்டுள்ள முதலமைச்சர் ஸ்டாலின் கூறியிருப்பதாவது :- தஞ்சாவூர்‌ மாவட்டம்‌, களிமேடு கிராமத்தில்‌ இன்று அதிகாலை நடைபெற்ற தேர்‌ திருவிழாவில்‌ எதிர்பாராத விதமாக தேர்‌ மின்கம்பியில்‌ உரசியதால்‌ ஏற்பட்ட விபத்தில்‌ 11 பேர்‌ சம்பவ இடத்திலேயே உயிரிழந்துவிட்டனர்‌ என்ற துயரமான செய்தியினைக்‌ கேள்வியுற்று மிகுந்த வேதனையடைந்தேன்‌.உயிரிழந்தவர்களின்‌ குடும்பத்தாருக்கு எனது ஆழ்ந்த இரங்கலைத்‌ தெரிவித்துக்கொள்கிறேன்‌.\\nமேலும்‌, இவ்விபத்தில்‌ 15 நபர்கள்‌ தற்போது சிகிச்சையில்‌ உள்ளதாக அறிகிறேன்‌, அவர்களுக்கு சிறப்பான சிகிச்சை அளிக்கவும்‌ விபத்து பகுதியில்‌ மிட்பு நடவடிக்கைகளை துரிதப்படுத்தவும்‌ மாவட்ட நிர்வாகத்திற்கும்‌, காவல்‌ துறைக்கும்‌ உத்தரவிட்டுள்ளேன்‌.\\nஇந்த விபத்தில்‌ உயிரிழந்தவர்களின்‌ குடும்பத்தாருக்கு தலா ஐந்து இலட்சம்‌ உடனடியாக முதலமைச்சரின்‌ பொது நிவாரண நிதியிலிருந்து நிதியுதவி வழங்கிட உத்தரவிட்டுள்ளேன்‌, எனக் குறிப்பிட்டுள்ளார். இதைத் தொடர்ந்து, தஞ்சை தேர் விபத்தில் உயிரிழந்த 11 பேருக்கு சட்டப்பேரவையில் உறுப்பினர்கள் இரங்கல் தெரிவித்தனர். இந்த இரங்கல் தீர்மானத்தை முதலமைச்சர் ஸ்டாலின் முன்மொழிந்தார்\\nஅதேவேளையில், தஞ்சையில் பலியான 11 பேரின் குடும்பத்திற்கு இரங்கல் தெரிவித்துக் கொண்ட பிரதமர் மோடி, காயமடைந்தவர்கள் விரைந்து மீண்டு வர வேண்டுவதாக கூறினார்.\\nமேலும், உயிரிந்தவர்களின் குடும்பத்திற்கு தலா ரூ.2 லட்சமும், காயமடைந்தவர்களுக்கு தலா ரூ.50 ஆயிரமும் நிவாரணம் வழங்கப்படும் என்று பிரதமர் மோடி அறிவித்தார்.\\nஎதிர்கட்சி தலைவர் எடப்பாடி பழனிசாமி விடுத்துள்ள இரங்கல் செய்தியில்,\\\"தஞ்சாவூர்,களிமேடு அப்பர் கோவில் தேர் திருவிழாவில் மின்சாரம் தாக்கி 11 பேர் உயிரிழந்தனர் என்ற செய்தியறிந்து மிகுந்த மனவேதனை அடைந்தேன். உயிரிழந்தோர் குடும்பத்தினருக்கு எனது ஆழ்ந்த இரங்கலை தெரிவித்து கொள்வதுடன், சிகிச்சை பெற்று வருவோர் பூரண நலம் பெற்று விரைவில் வீடு திரும்ப வேண்டுகிறேன். மரணமடைந்தோர் குடும்பத்துக்கு உரிய இழப்பீடும் , காயமடைந்தோர்க்கு தக்க நிவாரணமும் வழங்கி தமிழக அரசு உடனடி நடவடிக்கை எடுக்க வேண்டும்,\\\" என குறிப்பிட்டுள்ளார்.\\nபாஜக மாநில தலைவர் அண்ணாமலை வெளியிட்டுள்ள டுவிட்டர் பதிவில், \\\"தஞ்சை களிமேடு தேர் பவனி விபத்து செய்தியை கேள்விபட்டு மிகவும் துயரத்தில் உள்ளேன். 3 சிறுவர்கள் உட்பட மொத்தம் 11 பேர் இந்த சம்பவத்தில் உயிரிழந்துள்ளனர் என்பதை மனம் ஏற்க மறுக்கின்றது. உயிரிழந்தவர்களின் குடும்பத்தினருக்கு ஆழ்ந்த இரங்கலை தெரிவித்து கொள்கின்றேன். இனி இது போன்ற தேர் விபத்துக்கள் மூலம் உயிரிழப்புகள் நடைபெறாமல் தடுக்க தமிழக அரசு உயர்மட்ட குழுவை உடனடியாக அமைக்க வேண்டும்!, என வலியுறுத்தினார்.\\nஇதேபோல, குடியரசு தலைவர் ராம்நாத் கோவிந்த், தமிழக ஆளுநர் ஆர்என் ரவி, புதுச்சேரி ஆளுநர் தமிழிசை சவுந்தரராஜன் உள்ளிட்ட பல அரசியல் தலைவர்களும் இரங்கலை வெளியிட்டு வருகின்றனர்.\\nTags: MK stalin, PM Modi, அரசியல், எடப்பாடி பழனிசாமி, தஞ்சை, பாஜக தலைவர் அண்ணாமலை, பிரதமர் மோடி, முதலமைச்சர் ஸ்டாலின்\\nPrevious தேர்த்திருவிழாவில் 11 பேர் பலியானது எப்படி..? ஐஜி பாலகிருஷ்ணன் வெளியிட்ட தகவல்..!!\\nNext இந்தியாவில் 3 ஆயிரத்தை நெருங்கும் தினசரி பாதிப்பு… அனைத்து மாநில முதலமைச்சர்களுடன் பிரதமர் மோடி இன்று முக்கிய ஆலோசனை\",\n",
      "  \"timestamp\": \"2022/06/26 13:26:44\",\n",
      "  \"url\": \"https://www.updatenews360.com/trending/thanjai-car-festival-11-dead-political-leader-condolence-270422/\",\n",
      "  \"source\": \"mC4\"\n",
      "}\n",
      "{\n",
      "  \"text\": \"வடக்கின் வசந்தத்திற்கு, கிழக்கின் வடிவெள்ளிகளுக்கு….கோமணம் கூட கொடுபடவில்லை!\\nநான் பாடசாலை மாணவனாக இருந்த காலத்தில் பாடசாலைக்கு செல்லும்போது, வீதி வியாபாரிகள் தேங்காய், மாங்காய், பட்டாணிச் சுண்டல், ஓட்டை-ஒடிசல் அடியுண்ட-அடிபுண்ட சட்டி பானைகள் இருக்கா என்ற ஓங்கார ஒலிகொண்ட கூவியழைப்புடன் வியாபாரம் செய்வார்கள்! இந்த \\\"றேஞ்ச்\\\"சில் தான் 2012-ற்கான வரவு-செலலுத் திட்டத்தை வாசித்துள்ளார் மகிந்தர்!\\nஇவரின் வரவு-செலவை எப்படிப் (கூட்டி, கழித்து, பெருக்கி, பிரித்துப்) பார்த்தாலும் எஞ்சி-மிஞ்சி நிற்பது வெறும் சீரோ(0)தான்! இது தான் நாட்டுமக்களிற்கான எதிர்காலப் பயன்பாடும்!\\nபாராளுமன்றத்திற்கு \\\"அத்தி பூத்தால்ப் போல்த் தான் வருவார்\\\" யாரில் முழித்து வந்தாரோ தெரியவில்லை! இம்முறை வருகை எதிர்க்கட்சியினரின் தாக்குதல்கள், இவரின் அடியாட்களின் எதிர்தாக்குதல் சண்டைக்காட்சிகளாகத்தான் இருந்தது! இதையும் ரசித்துத்தான் வாசிக்க நேர்ந்ததது…வரவு எட்டணா, செலலு பதினாறு அணா என்ற இவரின் வ.செ. எனும் திட்டத்தை!\\nபாரிய இனவழிப்பின் பின் முட்கம்பி வேலிக்குள் அவலமான அகதிமுகாம் வாழ்வு வாழ்ந்த மக்கள், மீள்குடியேற்றத்தில் அதனிலும் கேவலமான வாழ்வையே வாழ்கின்றார்கள்! இதற்குள் வடகிழக்கில் வாழ்விழந்து வாழும் அபலைப் பெண்கள் பல்லாயிரக்கணக்கில்….பாதுகாப்புப் படையினரின் ஒவ்வொரு பெற்றோருக்கும் தலா 750- கொடுக்க முடியும், ஆனால் இவர்களுக்கு ஓர் 500-வது….?\\nகுடாநாட்டின் அபிவிருத்திப் பணிகளுக்கு அவசரமாக 14 ஆயிரம் மில்லியன் ருபா தேவையென சுவீடன் உயர் அதிகாரிகளிடம் யாழ் அரசாங்க அதிபர் தெரிவித்துள்ளார்! இதில் 14,000-ரூபாவது வடகிழக்கு பணிகளுக்கு ஒதுக்கப்பட்டுள்ளதா? இதை \\\"பட்டுவேட்டிக் கனவில் வாழும்\\\" வடக்கின் வசந்தத்திடமும், கிழக்கின் விடிவெள்ளிகளிடமும் கேட்கவேண்டியுள்ளது? தன்மான இணைப்பரசியலாளர்களே…! வரவு-செலவுத் திட்டத்தில் கேவலம் உங்கள் கோவணங்களுக்காவது?….\\nஇந்த லட்சண்தில் தான் புலன்(ம்) பெயர்ந்த சில சாதிச்சங்க பிரமுகர்களும், ஓடுக்கப்பட்ட தலித் மக்களுக்கு மகிந்தாவுடன் எம். சி. சுப்பிரமணிய \\\"இணைப்பரசியல்\\\" நடாத்தப் போகின்றார்களாம்! இதற்கு மந்திரியைக் கூப்பிட்டு தேசியப்பட்டியலில் எம்.பி. பதவியும் கேட்கின்றார்கள்! மகிந்த மடியில் விளையாடும் டக்கிளஸ்-பிள்ளையான்-கருணாவிற்கே வரவு-செலவுத் திட்டத்தில் கோவணம் கூட இல்லை! அதுவும் உங்களுக்கு….?\",\n",
      "  \"timestamp\": \"2021/01/20 22:17:56\",\n",
      "  \"url\": \"https://ndpfront.com/index.php/133-news/essays/akilan/474-2012-01-27-132136\",\n",
      "  \"source\": \"mC4\"\n",
      "}\n",
      "{\n",
      "  \"text\": \"முஸ்லிம்களின் பாதுகாப்பு எது? : உலமா கட்சி கேள்வி | OnlineCeylon\\nHome » சிறப்பு கட்டுரைகள் » முஸ்லிம்களின் பாதுகாப்பு எது? : உலமா கட்சி கேள்வி\\nமுஸ்லிம்களின் பாதுகாப்பு எது? : உலமா கட்சி கேள்வி\\nNovember 3, 2015\\tin சிறப்பு கட்டுரைகள், பிரதான செய்திகள்\\nமுஸ்லிம்களை பாதுகாப்பதற்காகவே புலிகள் வட மாகாண முஸ்லிம்களை வெளியேற்றினர் என்பது உண்மையாயின் அவர்களின் முழு உடமைகளையும் கொள்ளையடித்துக்கொண்டு வெறும் 500 ரூபாவுடன் வெளியேற்றியதுதான் பாதுகாப்பா ? என உலமா கட்சித்தலைவர் மௌலவி முபாறக் அப்துல் மஜீத் கேட்டுள்ளார். இது பற்றிய ஊடகவியலாளரின் கேள்விக்கு பதில் தருகையில் அவர் மேலும் தெரிவித்ததவதுää\\nவட மாகாண முஸ்லிம்களின் வெளியேற்றம் என்பது இனச்சுத்திகரிப்பே தவிர வேறில்லை. ஓர் இனத்தை முழுவதுமாக வெளியேற்றியது மட்டுமன்றி அவர்களின் உடமைகள் அனைத்தும் கொள்ளையடிக்கப்பட்டதன் மூலம் இதுவொரு மோசமான இனச்சுத்திகரிப்பாகும். இதற்கு எதிர்ப்புத்தெரிவிக்காத அனைத்து தமிழ் மக்களும் வெட்கித்தலை குணிந்தே ஆக வேண்டும்.\\nமுஸ்லிம்களை வெளியேற்றியமை அவர்களுக்கு பாதுகாப்பாயின் புலி பயங்கரவாதிகளை அரசாங்கம் விடுதலை செய்யாமல் தற்போதும் சிறையில் வைத்திருப்பது அவர்களின் உயிர்களை பாதுகாக்கவே என அரசு சொல்லுமாயின் அதனை அரிய நேந்திரன் ஏற்பாரா என்று கேட்கிறோம்.\\nஅத்துடன் பிரேமதாசா ஆட்சிக்காலத்தில் புலிகளிடமிருந்து முஸ்லிம்களை பிரிக்கவே முஸ்லிம்களுக்கு ஆயுதம் வழங்கி தமிழர்களுக்கெதிரான நடவடிக்கை மேற்கொள்ளப்பட்டது என அரிய நேந்திரன் கூறுவதன் மூலம் அவருக்கு இந்த நாட்டின் யுத்தகால வரலாறு தெரியாது என்பது புலனாகின்றது. 1990ல் பிரேமதாசவின் அரசும் புலிகளும் தேனிலவு உறவாடிக்கொண்டிருக்கும் போதுதான் கல்முனை காத்தான்குடி போன்ற நகரங்களில் நூற்றுக்கணக்கான முஸ்லிம் இளைஞர்களை புலிகள் சிறைப்பிடித்து சித்திரவதை செய்தனர். அவர்களில் பலருக்கு என்ன நடந்தது என்று இது வரை தெரியவில்லை. இதற்கு எதிராக பிரேமதாச அரசு எத்தகை நடவடிக்கையும் எடுக்கவில்லை. இதே கால பகுதியிலேயே வடக்கில் பல முஸ்லிம்கள் சிறைபிடிக்கப்பட்டதுடன் சிலர் புலிகளால் கொல்லப்பட்டனர். புலிகளின் முஸ்லிம்களுக்கெதிரான நடவடிக்கைகளின் போது மௌனமாக இருந்த பிரேமதாச அரசு முஸ்லிம்களுக்கு ஆயுதம் வழங்கியது என்பது அர்த்தமற்ற கூற்றாகும்.\\nஉண்மையில் புலிகள் மற்றும் ஆயுதம் தாங்கிய தமிழ் குழுக்களின் முஸ்லிம்களுக்கெதிரான செயற்பாடுகள் 1985 முதலே ஆரம்பமாகி விட்டன. இதன் காரணமாக அக்கரைப்பற்று சம்பவம்ää காரைதீவு சம்பவம்ää உண்ணிச்சை கிராம முஸ்லிம்களை பாதுகாப்பு தருகிறோம் வெளியேறவேண்டாம் பாதுகாப்பு தருகிறோம் என கூறி மொத்தமாக அவர்களை எரித்ததுää வியாபாரத்துக்காக சென்ற முஸ்லிம்களிடம் அவர்களிடமிருந்த ஐயாயிரம் ரூபாவுக்காக அவர்களை கொலை செய்தமை போன்ற கொடூர சம்பவங்கள் நடைபெற்றன. இந்த வேளைகளில் பிரேமதாச அரசு இருக்கவுமில்லை முஸ்லிம் ஊர்காவற்படையினர் நியமிக்கப்பட்டிருக்கவுமில்லை என்பது ஒரு பாராளுமன்ற உறுப்பினராக இருந்த அரியநேந்திரனுக்கு தெரியாமல் போய் விட்டதா அல்லது அவர் உண்மையை மறைக்கிறாரா?\\nஆக வட மாகாண முஸ்லிம்கள் அனைத்து உடமைகளும் கொள்ளையடிக்கப்பட்ட பின் வெளியேற்றப்பட்டமை பாரிய இனச்சுத்திகரிப்பாகும். இதனை வட மாகாண தமிழ் மக்கள் உணர்ந்து அம்மக்களிடம் கொள்ளையடித்த அனைத்தையும் மீள வழங்கி அவர்களை அவர்களது சொந்த இடங்களில் மீள குடியேற்ற நடவடிக்கை எடுப்பதே தமிழ் மக்களின் தனிப்பண்பை எடுத்துக்காட்டுவதாக அமையும்.\",\n",
      "  \"timestamp\": \"2017/12/11 09:19:32\",\n",
      "  \"url\": \"http://onlineceylon.com/?p=975\",\n",
      "  \"source\": \"mC4\"\n",
      "}\n",
      "\n",
      "Columns: ['text', 'timestamp', 'url', 'source']\n",
      "Shape: (50, 4)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"data/culturax_tamil_subset.jsonl\"\n",
    "\n",
    "# Read first 5 lines manually (to inspect structure)\n",
    "with open(file_path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        sample = json.loads(line)\n",
    "        print(json.dumps(sample, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Also quickly check number of fields in first line\n",
    "df_sample = pd.read_json(file_path, lines=True, nrows=50)\n",
    "print(\"\\nColumns:\", df_sample.columns.tolist())\n",
    "print(\"Shape:\", df_sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19677f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic stats:\n",
      "            char_len  english_frac\n",
      "count   10000.000000  10000.000000\n",
      "mean     3455.811400      0.037460\n",
      "std      5495.700495      0.055683\n",
      "min       101.000000      0.000000\n",
      "25%      1291.000000      0.006016\n",
      "50%      2004.000000      0.018728\n",
      "75%      3510.500000      0.044700\n",
      "max    162315.000000      0.532642\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Threshold examples\u001b[39;00m\n\u001b[32m     16\u001b[39m high_english = df[df[\u001b[33m\"\u001b[39m\u001b[33menglish_frac\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0.3\u001b[39m].sample(\u001b[32m3\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m short_texts = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchar_len\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- High English Fraction Examples ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m high_english[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/bilingual-tamil-llm/venv/lib/python3.13/site-packages/pandas/core/generic.py:6140\u001b[39m, in \u001b[36mNDFrame.sample\u001b[39m\u001b[34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[39m\n\u001b[32m   6137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   6138\u001b[39m     weights = sample.preprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[32m-> \u001b[39m\u001b[32m6140\u001b[39m sampled_indices = \u001b[43msample\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6141\u001b[39m result = \u001b[38;5;28mself\u001b[39m.take(sampled_indices, axis=axis)\n\u001b[32m   6143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/bilingual-tamil-llm/venv/lib/python3.13/site-packages/pandas/core/sample.py:152\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(obj_len, size, replace, weights, random_state)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid weights: weights sum to zero\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m.astype(\n\u001b[32m    153\u001b[39m     np.intp, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    154\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:945\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load a small chunk (e.g. 10k rows for fast inspection)\n",
    "file_path = \"data/culturax_tamil_subset.jsonl\"\n",
    "df = pd.read_json(file_path, lines=True, nrows=10000)\n",
    "\n",
    "# Basic text stats\n",
    "df[\"char_len\"] = df[\"text\"].str.len()\n",
    "df[\"english_frac\"] = df[\"text\"].apply(lambda x: len(re.findall(r\"[A-Za-z]\", x)) / len(x) if len(x) > 0 else 0)\n",
    "\n",
    "print(\"Basic stats:\")\n",
    "print(df[[\"char_len\", \"english_frac\"]].describe())\n",
    "\n",
    "# Threshold examples\n",
    "high_english = df[df[\"english_frac\"] > 0.3].sample(3, random_state=42)\n",
    "short_texts = df[df[\"char_len\"] < 100].sample(3, random_state=42)\n",
    "\n",
    "print(\"\\n--- High English Fraction Examples ---\")\n",
    "for t in high_english[\"text\"]:\n",
    "    print(t[:300], \"\\n\")\n",
    "\n",
    "print(\"\\n--- Very Short Text Examples ---\")\n",
    "for t in short_texts[\"text\"]:\n",
    "    print(t[:300], \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd3f6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4778.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cleaned CulturaX Tamil subset: 9838 rows → data/processed/culturax_tamil_clean.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re, json, unicodedata, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_tamil(text):\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = text.replace(\"–\", \"-\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    return text\n",
    "\n",
    "cleaned = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row[\"text\"]\n",
    "    english_frac = len(re.findall(r\"[A-Za-z]\", text)) / len(text)\n",
    "    if english_frac < 0.25 and len(text) < 50000:\n",
    "        record = row.to_dict()\n",
    "        record[\"text\"] = normalize_tamil(text)\n",
    "        # 🧹 Convert pandas.Timestamp → str\n",
    "        if \"timestamp\" in record and not isinstance(record[\"timestamp\"], str):\n",
    "            record[\"timestamp\"] = str(record[\"timestamp\"])\n",
    "        cleaned.append(record)\n",
    "\n",
    "# Save cleaned file\n",
    "out_path = \"data/processed/culturax_tamil_clean.jsonl\"\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "with open(out_path, \"w\") as f:\n",
    "    for item in cleaned:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Saved cleaned CulturaX Tamil subset: {len(cleaned)} rows → {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40f92be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded cleaned CulturaX Tamil subset (first 20 rows)\n",
      "Columns: ['text', 'timestamp', 'url', 'source', 'char_len', 'english_frac']\n",
      "Shape: (20, 6)\n",
      "\n",
      "--- Sample Cleaned Entries ---\n",
      "\n",
      "குழந்தை பராமரிப்பு | தினகரன் Home குழந்தை பராமரிப்பு குழந்தைகளின் செய்கை மொழியை எளிதில் புரிந்து கொள்ள இயலாது. அழுகையும், சிரிப்புமே குழந்தையின் அழகிய மொழிகள். அதனை உணர்ந்து குழந்தைகளை வளர்ப்பது என்பது பெற்றோருக்கே உண்டான தனிக்கலை. பச்சிளம் குழந்தைகளின் செயல்பாடுகள் புரியாமல் சில நேரங்களில் தாய்மார்கள் எரிச்சல் அடைவதும் உண்டு. இங்கு குழந்தைகளை எவ்வாறு கையாள வேண்டும். 1. குழந்தைகள் முதலில் விரும்பு \n",
      "---\n",
      "\n",
      "வடகொரியாவால் மறக்க முடியாத நான்கு அமெரிக்க வீரர்கள் - BBC News தமிழ் வடகொரியாவால் மறக்க முடியாத நான்கு அமெரிக்க வீரர்கள் சைமன் ஃபவுலர் பிபிசி செய்தியாளர் 29 டிசம்பர் 2017 https://www.bbc.com/tamil/global-42492727 படத்தின் காப்புரிமை North Korea Picture Library / Alamy Stock Photo Image caption வடகொரியாவால் மறக்க முடியாத நான்கு அமெரிக்க வீரர்கள் வட கொரியாவில் திரைப்படங்களில் அமெரிக்க நட்சத்திரங்கள் \n",
      "---\n",
      "\n",
      "கிரேக்க நாடகாசிரியர் ஹோமர் அவர்கள் எழுதிய ஒடிசி பற்றிய சுருக்க வரைவு. - முனைவர் ர. தாரணி- 02 ஏப்ரல் 2017 மிக நீண்ட பயணத்தின் பல்வேறு பரிணாமங்கள் என்பதே ஒடிசி என்ற வார்த்தையின் பொருள். காலத்தால் அழியா கிரேக்க காவியமான ஹோமரின் ஒடிசி, காப்பிய நாயகனான யூலிஸிஸ் என்ற மாபெரும் கிரேக்க வீரனின் ஒரு நெடுந்தூர பயணத்தை விவரிக்கும் விதமாக அமைந்துள்ளது. கி. மு எட்டாம் நூற்றாண்டில் எழுதப்பெற்ற ஒடிசி ஹோமரின் முந் \n",
      "---\n",
      "\n",
      "\n",
      "Mean English fraction after cleaning: 0.0251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re\n",
    "\n",
    "clean_path = \"data/processed/culturax_tamil_clean.jsonl\"\n",
    "\n",
    "df_clean = pd.read_json(clean_path, lines=True, nrows=20)\n",
    "print(\"✅ Loaded cleaned CulturaX Tamil subset (first 20 rows)\")\n",
    "print(\"Columns:\", df_clean.columns.tolist())\n",
    "print(\"Shape:\", df_clean.shape)\n",
    "\n",
    "# Sample 3 random rows\n",
    "print(\"\\n--- Sample Cleaned Entries ---\\n\")\n",
    "for t in df_clean.sample(3, random_state=42)[\"text\"]:\n",
    "    print(t[:400], \"\\n---\\n\")\n",
    "\n",
    "# Sanity check: English fraction (should be very low)\n",
    "english_mean = df_clean[\"text\"].apply(lambda x: len(re.findall(r\"[A-Za-z]\", x)) / len(x)).mean()\n",
    "print(f\"\\nMean English fraction after cleaning: {english_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c693f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'text', 'system_prompt'],\n",
      "        num_rows: 51876\n",
      "    })\n",
      "})\n",
      "\n",
      "--- SAMPLE ---\n",
      "{'instruction': 'ஆரோக்கியமாக இருப்பதற்கு மூன்று குறிப்புகளைக் கொடுங்கள்.', 'input': '', 'output': '1. சமச்சீரான மற்றும் சத்தான உணவை உண்ணுங்கள்: உங்கள் உணவில் பலவகையான பழங்கள் மற்றும் காய்கறிகள், மெலிந்த புரதம், முழு தானியங்கள் மற்றும் ஆரோக்கியமான கொழுப்புகள் உள்ளன என்பதை உறுதிப்படுத்திக் கொள்ளுங்கள். இது உங்கள் உடலைச் சிறப்பாகச் செயல்பட தேவையான ஊட்டச்சத்துக்களுடன் வழங்க உதவுகிறது மற்றும் நாள்பட்ட நோய்களைத் தடுக்க உதவுகிறது.\\n\\n2. வழக்கமான உடல் செயல்பாடுகளில் ஈடுபடுங்கள்: வலுவான எலும்புகள், தசைகள் மற்றும் இருதய ஆரோக்கியத்தை பராமரிக்க உடற்பயிற்சி முக்கியமானது. ஒவ்வொரு வாரமும் குறைந்தபட்சம் 150 நிமிட மிதமான ஏரோபிக் உடற்பயிற்சி அல்லது 75 நிமிட தீவிரமான உடற்பயிற்சியை இலக்காகக் கொள்ளுங்கள்.\\n\\n3. போதுமான தூக்கத்தைப் பெறுங்கள்: போதுமான தரமான தூக்கம் உடல் மற்றும் மன நலனுக்கு முக்கியமானது. இது மனநிலையை சீராக்க உதவுகிறது, அறிவாற்றல் செயல்பாட்டை மேம்படுத்துகிறது மற்றும் ஆரோக்கியமான வளர்ச்சி மற்றும் நோயெதிர்ப்பு செயல்பாட்டை ஆதரிக்கிறது. ஒவ்வொரு இரவும் 7-9 மணிநேர தூக்கத்தை இலக்காகக் கொள்ளுங்கள்.', 'text': 'ஒரு பணியை எவ்வாறு நிறைவேற்ற வேண்டும் என்று கூறும் அறிவுரை கீழே உள்ளது. வேண்டுகோளைப் பொருத்தமாக நிறைவு செய்கின்ற பதில் ஒன்றை எழுதுக.\\n\\n### Instruction:\\nஆரோக்கியமாக இருப்பதற்கு மூன்று குறிப்புகளைக் கொடுங்கள்.\\n\\n### Response:\\n1. சமச்சீரான மற்றும் சத்தான உணவை உண்ணுங்கள்: உங்கள் உணவில் பலவகையான பழங்கள் மற்றும் காய்கறிகள், மெலிந்த புரதம், முழு தானியங்கள் மற்றும் ஆரோக்கியமான கொழுப்புகள் உள்ளன என்பதை உறுதிப்படுத்திக் கொள்ளுங்கள். இது உங்கள் உடலைச் சிறப்பாகச் செயல்பட தேவையான ஊட்டச்சத்துக்களுடன் வழங்க உதவுகிறது மற்றும் நாள்பட்ட நோய்களைத் தடுக்க உதவுகிறது.\\n\\n2. வழக்கமான உடல் செயல்பாடுகளில் ஈடுபடுங்கள்: வலுவான எலும்புகள், தசைகள் மற்றும் இருதய ஆரோக்கியத்தை பராமரிக்க உடற்பயிற்சி முக்கியமானது. ஒவ்வொரு வாரமும் குறைந்தபட்சம் 150 நிமிட மிதமான ஏரோபிக் உடற்பயிற்சி அல்லது 75 நிமிட தீவிரமான உடற்பயிற்சியை இலக்காகக் கொள்ளுங்கள்.\\n\\n3. போதுமான தூக்கத்தைப் பெறுங்கள்: போதுமான தரமான தூக்கம் உடல் மற்றும் மன நலனுக்கு முக்கியமானது. இது மனநிலையை சீராக்க உதவுகிறது, அறிவாற்றல் செயல்பாட்டை மேம்படுத்துகிறது மற்றும் ஆரோக்கியமான வளர்ச்சி மற்றும் நோயெதிர்ப்பு செயல்பாட்டை ஆதரிக்கிறது. ஒவ்வொரு இரவும் 7-9 மணிநேர தூக்கத்தை இலக்காகக் கொள்ளுங்கள்.\\n', 'system_prompt': 'ஒரு பணியை எவ்வாறு நிறைவேற்ற வேண்டும் என்று கூறும் அறிவுரை கீழே உள்ளது. வேண்டுகோளைப் பொருத்தமாக நிறைவு செய்கின்ற பதில் ஒன்றை எழுதுக.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "tamil_alpaca_path = \"data/tamil_alpaca\"\n",
    "tamil_alpaca = load_from_disk(tamil_alpaca_path)\n",
    "\n",
    "print(tamil_alpaca)\n",
    "print(\"\\n--- SAMPLE ---\")\n",
    "print(tamil_alpaca[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1e0195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE 18406 ---\n",
      "Instruction: ஐந்து செயல்பாடுகளின் பட்டியலை உருவாக்கவும், இது ஒரு நல்ல வார இறுதி பயணத்தை உருவாக்கும்.\n",
      "Output: 1. இயற்கையில் பயணம் செய்து உள்ளூர் பாதைகள் மற்றும் இயற்கைக்காட்சிகளை ஆராயுங்கள்.\n",
      "2. இப்பகுதியின் வரலாறு மற்றும் கலாச்சாரத்தைப் பற்றி அறிய ஒரு வரலாற்றுச் சுற்றுலா செல்லவும் அல்லது அருங்காட்சியகத்தைப் பார்வையிடவும்.\n",
      "3. சில புத்துணர்ச்சி மற்றும் சுய பாதுகாப்புக்காக ஸ்பா அல்லது சூடான நீரூற்றில் ஓய்வெடுக\n",
      "System Prompt: ஒரு பணியை எவ்வாறு நிறைவேற்ற வேண்டும் என்று கூறும் அறிவுரை கீழே உள்ளது. வேண்டுகோளைப் பொருத்தமாக நிறைவு செய்கின்ற பதில் ஒன்றை எழுதுக.\n",
      "\n",
      "--- SAMPLE 14832 ---\n",
      "Instruction: உங்கள் சொந்த ஊரைப் பற்றி ஒரு லிமெரிக் எழுதுங்கள்.\n",
      "Output: மிகவும் சிறிய மற்றும் மிகவும் பசுமையான ஒரு நகரத்தில்,\n",
      "மிகவும் அழகான இடத்தை பார்க்க முடியவில்லை,\n",
      "மக்கள் அனைவரும் புன்னகைக்கிறார்கள்,\n",
      "மேலும் கூடுதல் மைல் செல்லவும்,\n",
      "என் சொந்த ஊரில், வாழ்க்கை மிகவும் அமைதியாக இருக்கிறது.\n",
      "System Prompt: ஒரு பணியை எவ்வாறு நிறைவேற்ற வேண்டும் என்று கூறும் அறிவுரை கீழே உள்ளது. வேண்டுகோளைப் பொருத்தமாக நிறைவு செய்கின்ற பதில் ஒன்றை எழுதுக.\n",
      "\n",
      "--- SAMPLE 50249 ---\n",
      "Instruction: வெற்றிக்கான மூன்று குறிப்புகள் மற்றும் தந்திரங்களை கொடுங்கள்\n",
      "Output: 1. முன்னுரிமை மற்றும் ஒழுங்கமைத்தல்: பயனுள்ள நேர மேலாண்மை வெற்றிக்கு முக்கியமானது. தெளிவான இலக்குகளை அமைக்கவும், முக்கியத்துவம் மற்றும் காலக்கெடுவின் அடிப்படையில் பணிகளுக்கு முன்னுரிமை அளிக்கவும், அதற்கேற்ப உங்கள் அட்டவணையை ஒழுங்கமைக்கவும். இதன் மூலம், நீங்கள் செய்ய வேண்டியவற்றில் கவனம் செலுத்தலாம் \n",
      "System Prompt: ஒரு பணியை எவ்வாறு நிறைவேற்ற வேண்டும் என்று கூறும் அறிவுரை கீழே உள்ளது. வேண்டுகோளைப் பொருத்தமாக நிறைவு செய்கின்ற பதில் ஒன்றை எழுதுக.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample a few random rows for manual inspection\n",
    "for i in random.sample(range(len(tamil_alpaca[\"train\"])), 3):\n",
    "    row = tamil_alpaca[\"train\"][i]\n",
    "    print(f\"\\n--- SAMPLE {i} ---\")\n",
    "    print(\"Instruction:\", row[\"instruction\"][:200])\n",
    "    if row[\"input\"]:\n",
    "        print(\"Input:\", row[\"input\"][:200])\n",
    "    print(\"Output:\", row[\"output\"][:300])\n",
    "    print(\"System Prompt:\", row[\"system_prompt\"][:150])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d80952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51876/51876 [00:01<00:00, 36714.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Tamil Alpaca Clean JSONL → data/processed/tamil_alpaca_clean.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "tamil_alpaca_path = \"data/tamil_alpaca\"\n",
    "tamil_alpaca = load_from_disk(tamil_alpaca_path)\n",
    "\n",
    "output_path = \"data/processed/tamil_alpaca_clean.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    for ex in tqdm(tamil_alpaca[\"train\"]):\n",
    "        # Build minimal schema\n",
    "        clean_entry = {\n",
    "            \"instruction\": ex[\"instruction\"].strip(),\n",
    "            \"input\": ex[\"input\"].strip() if ex[\"input\"] else \"\",\n",
    "            \"output\": ex[\"output\"].strip()\n",
    "        }\n",
    "        json.dump(clean_entry, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Saved Tamil Alpaca Clean JSONL → {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080cca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99564fd52554796b4f608c9491a68e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported first 20 rows → nlpc_sample.jsonl\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the dataset\n",
    "nlpc_uom = load_from_disk(\"data/nlpc_uom_en_ta\")\n",
    "\n",
    "# Export first 20 samples for inspection\n",
    "nlpc_uom[\"train\"].select(range(20)).to_json(\"nlpc_sample.jsonl\", force_ascii=False, orient=\"records\", lines=True)\n",
    "\n",
    "print(\"✅ Exported first 20 rows → nlpc_sample.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec678fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlpc_uom_en_ta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnlpc_uom_en_ta\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m][i][\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'nlpc_uom_en_ta' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070a604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
